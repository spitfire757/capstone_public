{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4854458-6950-4baf-97f5-025f31dd22c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# MODEL for target pressure given temp and others, working on real time updat efor new data for some reason its called feautures\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "import joblib  # Import joblib for saving and loading models\n",
    "\n",
    "global LOC, data_path\n",
    "LOC = '/home/bkelley/capstone/data_collection/weather'\n",
    "data_path = '/home/bkelley/capstone/data_collection/weather/data/hourly_weather_with_temp_avg.csv'\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    \n",
    "    # Load data\n",
    "    data = pd.read_csv(data_path)\n",
    "    \n",
    "    # Extract feature and target arrays\n",
    "    x, y = data.drop('temperature_2m', axis=1), data[['surface_pressure_Pa']]\n",
    "    cats = x.select_dtypes(exclude=np.number).columns.tolist()\n",
    "    \n",
    "    for col in cats:\n",
    "        x[col] = x[col].astype('category')\n",
    "\n",
    "    # Split the data (size=0.25)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=1)\n",
    "\n",
    "    # Create regression matrices\n",
    "    dtrain_reg = xgb.DMatrix(x_train, y_train, enable_categorical=True)\n",
    "    dtest_reg = xgb.DMatrix(x_test, y_test, enable_categorical=True)\n",
    "\n",
    "    # Define hyperparameters\n",
    "    params = {\"objective\": \"reg:squarederror\", \"tree_method\": \"hist\"}\n",
    "    n = 200\n",
    "    evals = [(dtrain_reg, \"train\"), (dtest_reg, \"validation\")]\n",
    "    \n",
    "    # Train the model with early stopping\n",
    "    model = xgb.train(\n",
    "        params=params,\n",
    "        dtrain=dtrain_reg,\n",
    "        num_boost_round=n,\n",
    "        evals=evals,\n",
    "        verbose_eval=5,\n",
    "        early_stopping_rounds=50\n",
    "    )\n",
    "    \n",
    "    print('Model training done.')\n",
    "\n",
    "    # Save the trained model\n",
    "    model_filename = 'xgb_model_pres_temp.json'  # Specify your desired filename\n",
    "    model.save_model(model_filename)\n",
    "    print(f'Model saved to {model_filename}.')\n",
    "\n",
    "    # Make predictions\n",
    "    preds = model.predict(dtest_reg)\n",
    "    rmse = mean_squared_error(y_test, preds, squared=False)\n",
    "    print(f\"RMSE of the base model: {rmse:.3f}\")\n",
    "    print('Starting Cross - Validation....')\n",
    "    # 5-fold cross-validation\n",
    "    results = xgb.cv(\n",
    "        params, dtrain_reg,\n",
    "        num_boost_round=n,\n",
    "        nfold=5,\n",
    "        early_stopping_rounds=35\n",
    "    )\n",
    "    best_rmse = results['test-rmse-mean'].min()\n",
    "    print(f'Best RMSE from CV: {best_rmse:.3f}')\n",
    "\n",
    "# To load the model and make predictions later\n",
    "loaded_model = xgb.Booster()\n",
    "loaded_model.load_model(model_filename)\n",
    "\n",
    "# Prepare new data for prediction, making sure it matches the training data format\n",
    "new_data = pd.DataFrame({\n",
    "    'feature_1': [value1],\n",
    "    'feature_2': [value2],\n",
    "    # Add all features used in training\n",
    "})\n",
    "new_data = random_sample\n",
    "# Create DMatrix for the new data\n",
    "new_dmatrix = xgb.DMatrix(new_data, enable_categorical=True)\n",
    "\n",
    "# Make predictions with the loaded model\n",
    "predictions = loaded_model.predict(new_dmatrix)\n",
    "print(\"Predicted Pressure for new data:\", predictions)\n",
    "'''\n",
    "0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0536aa5a-f671-4f13-8f91-a26cf20779d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "# TEST set\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random_seed = 42\n",
    "\n",
    "# Required columns including 'date' but it will not be used for the model\n",
    "required_columns_with_date = ['date', 'relative_humidity_2m', 'precipitation', 'rain', 'weather_code', \n",
    "                              'surface_pressure', 'cloud_cover', 'wind_speed_10m', \n",
    "                              'wind_speed_100m', 'wind_direction_10m', 'wind_direction_100m', \n",
    "                              'temperature_2m_K', 'surface_pressure_Pa', 'density', 'speed_of_sound']\n",
    "\n",
    "# Grab 100 random rows with the random seed\n",
    "data_path = '/home/bkelley/capstone/data_collection/weather/data/hourly_weather_with_temp_avg.csv'\n",
    "\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "filtered_data = data[required_columns_with_date]\n",
    "\n",
    "random_sample = filtered_data.sample(n=100, random_state=random_seed)\n",
    "\n",
    "# Add placeholder 'date' column\n",
    "random_sample_with_date = random_sample.copy()\n",
    "random_sample_with_date['date'] = 0  # Placeholder value for 'date'\n",
    "\n",
    "# Now you can proceed with creating the DMatrix for the random sample with 'date'\n",
    "new_dmatrix = xgb.DMatrix(random_sample_with_date[required_columns_with_date], enable_categorical=True)\n",
    "\n",
    "# Make predictions with the loaded model\n",
    "predictions = loaded_model.predict(new_dmatrix)\n",
    "\n",
    "# Grab the actual surface pressure from the dataset\n",
    "actual_pressures = random_sample_with_date['surface_pressure_Pa'].values\n",
    "\n",
    "# Grab the temperature values from the dataset\n",
    "temperature_values = random_sample_with_date['temperature_2m_K'].values\n",
    "\n",
    "# Create a DataFrame with predicted, actual, and temperature columns\n",
    "results_df = pd.DataFrame({\n",
    "    'Predicted Pressure': predictions,\n",
    "    'Actual Pressure': actual_pressures,\n",
    "    'Temperature (K)': temperature_values\n",
    "})\n",
    "\n",
    "# Convert pressures from Pa to hPa (hectopascals or millibars)\n",
    "results_df['Predicted Pressure'] = results_df['Predicted Pressure'] / 100\n",
    "results_df['Actual Pressure'] = results_df['Actual Pressure'] / 100\n",
    "\n",
    "# Display the DataFrame\n",
    "print(results_df)\n",
    "'''\n",
    "print(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581d22df-6d19-4892-9015-026e00b5b2a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:494.29147\tvalidation-rmse:494.44767\n",
      "[5]\ttrain-rmse:85.12554\tvalidation-rmse:88.19774\n",
      "[10]\ttrain-rmse:20.19447\tvalidation-rmse:31.47241\n",
      "[15]\ttrain-rmse:12.26312\tvalidation-rmse:27.75708\n",
      "[20]\ttrain-rmse:10.78677\tvalidation-rmse:27.65372\n",
      "[25]\ttrain-rmse:9.92034\tvalidation-rmse:27.59705\n",
      "[30]\ttrain-rmse:9.36951\tvalidation-rmse:27.60585\n",
      "[35]\ttrain-rmse:8.85537\tvalidation-rmse:27.60292\n",
      "[40]\ttrain-rmse:8.46825\tvalidation-rmse:27.61352\n",
      "[45]\ttrain-rmse:8.08535\tvalidation-rmse:27.61024\n",
      "[50]\ttrain-rmse:7.80327\tvalidation-rmse:27.62141\n",
      "[55]\ttrain-rmse:7.52581\tvalidation-rmse:27.62151\n",
      "[60]\ttrain-rmse:7.27578\tvalidation-rmse:27.62667\n",
      "[65]\ttrain-rmse:7.08114\tvalidation-rmse:27.63788\n",
      "[70]\ttrain-rmse:6.90646\tvalidation-rmse:27.64899\n",
      "[73]\ttrain-rmse:6.80911\tvalidation-rmse:27.65563\n",
      "Model training done.\n",
      "Model saved to /home/bkelley/capstone/data_collection/weather/xgb_model_pres_temp.json.\n",
      "RMSE of the base model: 27.656\n",
      "Starting Cross - Validation....\n"
     ]
    }
   ],
   "source": [
    "# FINAL DEV \n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "import joblib  # Import joblib for saving and loading models\n",
    "\n",
    "# Global variables for paths\n",
    "global LOC, data_path\n",
    "LOC = '/home/bkelley/capstone/data_collection/weather'\n",
    "data_path = f'{LOC}/data/hourly_weather_with_temp_avg.csv'\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random_seed = 42\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    \n",
    "    # Load data\n",
    "    data = pd.read_csv(data_path)\n",
    "    \n",
    "    # Extract feature and target arrays\n",
    "    x, y = data.drop('temperature_2m', axis=1), data[['surface_pressure_Pa']]\n",
    "    cats = x.select_dtypes(exclude=np.number).columns.tolist()\n",
    "    \n",
    "    for col in cats:\n",
    "        x[col] = x[col].astype('category')\n",
    "\n",
    "    # Split the data (size=0.25)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=1)\n",
    "\n",
    "    # Create regression matrices\n",
    "    dtrain_reg = xgb.DMatrix(x_train, y_train, enable_categorical=True)\n",
    "    dtest_reg = xgb.DMatrix(x_test, y_test, enable_categorical=True)\n",
    "\n",
    "    # Define hyperparameters\n",
    "    params = {\"objective\": \"reg:squarederror\", \"tree_method\": \"hist\"}\n",
    "    n = 200\n",
    "    evals = [(dtrain_reg, \"train\"), (dtest_reg, \"validation\")]\n",
    "    \n",
    "    # Train the model with early stopping\n",
    "    model = xgb.train(\n",
    "        params=params,\n",
    "        dtrain=dtrain_reg,\n",
    "        num_boost_round=n,\n",
    "        evals=evals,\n",
    "        verbose_eval=5,\n",
    "        early_stopping_rounds=50\n",
    "    )\n",
    "    \n",
    "    print('Model training done.')\n",
    "\n",
    "    # Save the trained model\n",
    "    model_filename = f'{LOC}/xgb_model_pres_temp.json'\n",
    "    model.save_model(model_filename)\n",
    "    print(f'Model saved to {model_filename}.')\n",
    "\n",
    "    # Make predictions\n",
    "    preds = model.predict(dtest_reg)\n",
    "    rmse = mean_squared_error(y_test, preds, squared=False)\n",
    "    print(f\"RMSE of the base model: {rmse:.3f}\")\n",
    "    print('Starting Cross - Validation....')\n",
    "\n",
    "    # 5-fold cross-validation\n",
    "    results = xgb.cv(\n",
    "        params, dtrain_reg,\n",
    "        num_boost_round=n,\n",
    "        nfold=5,\n",
    "        early_stopping_rounds=35\n",
    "    )\n",
    "    best_rmse = results['test-rmse-mean'].min()\n",
    "    print(f'Best RMSE from CV: {best_rmse:.3f}')\n",
    "\n",
    "# To load the model and make predictions later\n",
    "loaded_model = xgb.Booster()\n",
    "loaded_model.load_model(model_filename)\n",
    "\n",
    "# Required columns including 'date' but it will not be used for the model\n",
    "required_columns_with_date = ['date', 'relative_humidity_2m', 'precipitation', 'rain', 'weather_code', \n",
    "                              'surface_pressure', 'cloud_cover', 'wind_speed_10m', \n",
    "                              'wind_speed_100m', 'wind_direction_10m', 'wind_direction_100m', \n",
    "                              'temperature_2m_K', 'surface_pressure_Pa', 'density', 'speed_of_sound']\n",
    "\n",
    "# Load the data again to sample new rows\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "# Filter the data for required columns\n",
    "filtered_data = data[required_columns_with_date]\n",
    "\n",
    "# Grab 100 random rows with the random seed\n",
    "random_sample = filtered_data.sample(n=100, random_state=random_seed)\n",
    "\n",
    "# Add placeholder 'date' column\n",
    "random_sample_with_date = random_sample.copy()\n",
    "random_sample_with_date['date'] = 0  # Placeholder value for 'date'\n",
    "\n",
    "# Create DMatrix for the random sample with 'date'\n",
    "new_dmatrix = xgb.DMatrix(random_sample_with_date[required_columns_with_date], enable_categorical=True)\n",
    "\n",
    "# Make predictions with the loaded model\n",
    "predictions = loaded_model.predict(new_dmatrix)\n",
    "\n",
    "# Grab the actual surface pressure from the dataset\n",
    "actual_pressures = random_sample_with_date['surface_pressure_Pa'].values\n",
    "\n",
    "# Grab the temperature values from the dataset\n",
    "temperature_values = random_sample_with_date['temperature_2m_K'].values\n",
    "\n",
    "# Create a DataFrame with predicted, actual, and temperature columns\n",
    "results_df = pd.DataFrame({\n",
    "    'Predicted Pressure': predictions,\n",
    "    'Actual Pressure': actual_pressures,\n",
    "    'Temperature (K)': temperature_values\n",
    "})\n",
    "\n",
    "# Convert pressures from Pa to hPa (hectopascals or millibars)\n",
    "results_df['Predicted Pressure'] = results_df['Predicted Pressure'] / 100\n",
    "results_df['Actual Pressure'] = results_df['Actual Pressure'] / 100\n",
    "\n",
    "# Display the DataFrame\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8f92b3d-3dfd-458a-bab9-6be634cf8f7c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 9\u001b[0m\n\u001b[1;32m      3\u001b[0m required_columns_with_date \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelative_humidity_2m\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecipitation\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrain\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweather_code\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      4\u001b[0m                               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurface_pressure\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcloud_cover\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwind_speed_10m\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      5\u001b[0m                               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwind_speed_100m\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwind_direction_10m\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwind_direction_100m\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      6\u001b[0m                               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtemperature_2m_K\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurface_pressure_Pa\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdensity\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspeed_of_sound\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Load the data again to sample new rows\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(data_path)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Filter the data for required columns\u001b[39;00m\n\u001b[1;32m     12\u001b[0m filtered_data \u001b[38;5;241m=\u001b[39m data[required_columns_with_date]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "random_seed = 1235\n",
    "# Required columns including 'date' but it will not be used for the model\n",
    "required_columns_with_date = ['date', 'relative_humidity_2m', 'precipitation', 'rain', 'weather_code', \n",
    "                              'surface_pressure', 'cloud_cover', 'wind_speed_10m', \n",
    "                              'wind_speed_100m', 'wind_direction_10m', 'wind_direction_100m', \n",
    "                              'temperature_2m_K', 'surface_pressure_Pa', 'density', 'speed_of_sound']\n",
    "\n",
    "# Load the data again to sample new rows\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "# Filter the data for required columns\n",
    "filtered_data = data[required_columns_with_date]\n",
    "\n",
    "# Grab 100 random rows with the random seed\n",
    "random_sample = filtered_data.sample(n=100, random_state=random_seed)\n",
    "\n",
    "# Add placeholder 'date' column\n",
    "random_sample_with_date = random_sample.copy()\n",
    "random_sample_with_date['date'] = 0  # Placeholder value for 'date'\n",
    "\n",
    "# Create DMatrix for the random sample with 'date'\n",
    "new_dmatrix = xgb.DMatrix(random_sample_with_date[required_columns_with_date], enable_categorical=True)\n",
    "\n",
    "# Make predictions with the loaded model\n",
    "predictions = loaded_model.predict(new_dmatrix)\n",
    "\n",
    "# Grab the actual surface pressure from the dataset\n",
    "actual_pressures = random_sample_with_date['surface_pressure_Pa'].values\n",
    "\n",
    "# Grab the temperature values from the dataset\n",
    "temperature_values = random_sample_with_date['temperature_2m_K'].values\n",
    "\n",
    "# Create a DataFrame with predicted, actual, and temperature columns\n",
    "results_df = pd.DataFrame({\n",
    "    'Predicted Pressure': predictions,\n",
    "    'Actual Pressure': actual_pressures,\n",
    "    'Temperature (K)': temperature_values\n",
    "})\n",
    "\n",
    "# Convert pressures from Pa to hPa (hectopascals or millibars)\n",
    "results_df['Predicted Pressure'] = results_df['Predicted Pressure'] / 100\n",
    "results_df['Actual Pressure'] = results_df['Actual Pressure'] / 100\n",
    "\n",
    "# Display the DataFrame\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ec8849-9a76-4035-968d-bec869a4a19e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
