{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b10a58-adcf-4da7-88a2-efb97aa07ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinates 24.428821563720703°N -124.96263122558594°E\n",
      "Timezone: Etc/GMT+8, Abbreviation: -08\n",
      "Data saved for 123 at (24.396308, -125.0)\n",
      "Coordinates 24.428821563720703°N -118.52720642089844°E\n",
      "Timezone: Etc/GMT+8, Abbreviation: -08\n",
      "Data saved for 123 at (24.396308, -118.54828555555555)\n",
      "Coordinates 24.428821563720703°N -112.09176635742188°E\n",
      "Timezone: America/Mazatlan, Abbreviation: MST\n",
      "Data saved for 123 at (24.396308, -112.0965711111111)\n",
      "Coordinates 24.428821563720703°N -105.56028747558594°E\n",
      "Timezone: America/Monterrey, Abbreviation: CST\n",
      "Data saved for 123 at (24.396308, -105.64485666666667)\n",
      "Coordinates 24.428821563720703°N -99.22091674804688°E\n",
      "Timezone: America/Monterrey, Abbreviation: CST\n",
      "Data saved for 123 at (24.396308, -99.19314222222222)\n",
      "Coordinates 24.428821563720703°N -92.78546142578125°E\n",
      "Timezone: Etc/GMT+6, Abbreviation: -06\n",
      "Data saved for 123 at (24.396308, -92.74142777777777)\n",
      "Coordinates 24.428821563720703°N -86.25399780273438°E\n",
      "Timezone: Etc/GMT+6, Abbreviation: -06\n",
      "Data saved for 123 at (24.396308, -86.28971333333334)\n",
      "Coordinates 24.428821563720703°N -79.81857299804688°E\n",
      "Timezone: America/Nassau, Abbreviation: EST\n",
      "Data saved for 123 at (24.396308, -79.83799888888889)\n",
      "Coordinates 24.428821563720703°N -73.38311767578125°E\n",
      "Timezone: Etc/GMT+5, Abbreviation: -05\n",
      "Data saved for 123 at (24.396308, -73.38628444444444)\n",
      "Coordinates 24.428821563720703°N -66.94769287109375°E\n",
      "Timezone: Etc/GMT+4, Abbreviation: -04\n",
      "Data saved for 123 at (24.396308, -66.93457)\n",
      "Coordinates 27.170473098754883°N -124.97773742675781°E\n",
      "Timezone: Etc/GMT+8, Abbreviation: -08\n",
      "Data saved for 123 at (27.172758, -125.0)\n",
      "Coordinates 27.170473098754883°N -118.5634765625°E\n",
      "Timezone: Etc/GMT+8, Abbreviation: -08\n",
      "Data saved for 123 at (27.172758, -118.54828555555555)\n",
      "Coordinates 27.170473098754883°N -112.04901123046875°E\n",
      "Timezone: America/Mazatlan, Abbreviation: MST\n",
      "Data saved for 123 at (27.172758, -112.0965711111111)\n",
      "Coordinates 27.170473098754883°N -105.63475036621094°E\n",
      "Timezone: America/Chihuahua, Abbreviation: CST\n",
      "Data saved for 123 at (27.172758, -105.64485666666667)\n",
      "Coordinates 27.170473098754883°N -99.22048950195312°E\n",
      "Timezone: America/Chicago, Abbreviation: CST\n",
      "Data saved for 123 at (27.172758, -99.19314222222222)\n",
      "Coordinates 27.170473098754883°N -92.70602416992188°E\n",
      "Timezone: Etc/GMT+6, Abbreviation: -06\n",
      "Data saved for 123 at (27.172758, -92.74142777777777)\n",
      "Coordinates 27.170473098754883°N -86.29177856445312°E\n",
      "Timezone: Etc/GMT+6, Abbreviation: -06\n",
      "Data saved for 123 at (27.172758, -86.28971333333334)\n",
      "Coordinates 27.170473098754883°N -79.87750244140625°E\n",
      "Timezone: Etc/GMT+5, Abbreviation: -05\n",
      "Data saved for 123 at (27.172758, -79.83799888888889)\n",
      "Coordinates 27.170473098754883°N -73.363037109375°E\n",
      "Timezone: Etc/GMT+5, Abbreviation: -05\n",
      "Data saved for 123 at (27.172758, -73.38628444444444)\n",
      "Coordinates 27.170473098754883°N -66.94879150390625°E\n",
      "Timezone: Etc/GMT+4, Abbreviation: -04\n",
      "Data saved for 123 at (27.172758, -66.93457)\n",
      "Coordinates 29.982423782348633°N -125.03495788574219°E\n",
      "Timezone: Etc/GMT+8, Abbreviation: -08\n",
      "Data saved for 123 at (29.949208, -125.0)\n",
      "Coordinates 29.982423782348633°N -118.53146362304688°E\n",
      "Timezone: Etc/GMT+8, Abbreviation: -08\n",
      "Data saved for 123 at (29.949208, -118.54828555555555)\n",
      "Coordinates 29.982423782348633°N -112.13285827636719°E\n",
      "Timezone: America/Hermosillo, Abbreviation: MST\n",
      "Data saved for 123 at (29.949208, -112.0965711111111)\n",
      "Coordinates 29.982423782348633°N -105.62936401367188°E\n",
      "Timezone: America/Ojinaga, Abbreviation: CST\n",
      "Data saved for 123 at (29.949208, -105.64485666666667)\n",
      "Coordinates 29.982423782348633°N -99.23077392578125°E\n",
      "Timezone: America/Chicago, Abbreviation: CST\n",
      "Data saved for 123 at (29.949208, -99.19314222222222)\n",
      "Coordinates 29.982423782348633°N -92.72726440429688°E\n",
      "Timezone: America/Chicago, Abbreviation: CST\n",
      "Data saved for 123 at (29.949208, -92.74142777777777)\n",
      "Coordinates 29.982423782348633°N -86.32867431640625°E\n",
      "Timezone: Etc/GMT+6, Abbreviation: -06\n",
      "Data saved for 123 at (29.949208, -86.28971333333334)\n",
      "Coordinates 29.982423782348633°N -79.82516479492188°E\n",
      "Timezone: Etc/GMT+5, Abbreviation: -05\n",
      "Data saved for 123 at (29.949208, -79.83799888888889)\n",
      "Coordinates 29.982423782348633°N -73.42657470703125°E\n",
      "Timezone: Etc/GMT+5, Abbreviation: -05\n",
      "Data saved for 123 at (29.949208, -73.38628444444444)\n",
      "Coordinates 29.982423782348633°N -66.92306518554688°E\n",
      "Timezone: Etc/GMT+4, Abbreviation: -04\n",
      "Data saved for 123 at (29.949208, -66.93457)\n",
      "Coordinates 32.72407531738281°N -125.05494689941406°E\n",
      "Timezone: Etc/GMT+8, Abbreviation: -08\n",
      "Data saved for 123 at (32.725657999999996, -125.0)\n",
      "Coordinates 32.72407531738281°N -118.57142639160156°E\n",
      "Timezone: America/Los_Angeles, Abbreviation: PST\n",
      "Data saved for 123 at (32.725657999999996, -118.54828555555555)\n",
      "Coordinates 32.72407531738281°N -112.19779968261719°E\n",
      "Timezone: America/Phoenix, Abbreviation: MST\n",
      "Data saved for 123 at (32.725657999999996, -112.0965711111111)\n",
      "Coordinates 32.72407531738281°N -105.71427917480469°E\n",
      "Timezone: America/Denver, Abbreviation: MST\n",
      "Data saved for 123 at (32.725657999999996, -105.64485666666667)\n",
      "Coordinates 32.72407531738281°N -99.23077392578125°E\n",
      "Timezone: America/Chicago, Abbreviation: CST\n",
      "Data saved for 123 at (32.725657999999996, -99.19314222222222)\n",
      "Coordinates 32.72407531738281°N -92.74725341796875°E\n",
      "Timezone: America/Chicago, Abbreviation: CST\n",
      "Data saved for 123 at (32.725657999999996, -92.74142777777777)\n",
      "Coordinates 32.72407531738281°N -86.26373291015625°E\n",
      "Timezone: America/Chicago, Abbreviation: CST\n",
      "Data saved for 123 at (32.725657999999996, -86.28971333333334)\n",
      "Coordinates 32.72407531738281°N -80.0°E\n",
      "Timezone: America/New_York, Abbreviation: EST\n",
      "Data saved for 123 at (32.725657999999996, -79.83799888888889)\n",
      "Coordinates 32.72407531738281°N -73.40658569335938°E\n",
      "Timezone: Etc/GMT+5, Abbreviation: -05\n",
      "Data saved for 123 at (32.725657999999996, -73.38628444444444)\n",
      "Coordinates 32.72407531738281°N -66.92306518554688°E\n",
      "Timezone: Etc/GMT+4, Abbreviation: -04\n",
      "Data saved for 123 at (32.725657999999996, -66.93457)\n",
      "Coordinates 35.53602600097656°N -125.00642395019531°E\n",
      "Timezone: Etc/GMT+8, Abbreviation: -08\n",
      "Data saved for 123 at (35.502108, -125.0)\n",
      "Coordinates 35.53602600097656°N -118.53659057617188°E\n",
      "Timezone: America/Los_Angeles, Abbreviation: PST\n",
      "Data saved for 123 at (35.502108, -118.54828555555555)\n",
      "Coordinates 35.53602600097656°N -112.06675720214844°E\n",
      "Timezone: America/Phoenix, Abbreviation: MST\n",
      "Data saved for 123 at (35.502108, -112.0965711111111)\n",
      "Coordinates 35.53602600097656°N -105.48138427734375°E\n",
      "Timezone: America/Denver, Abbreviation: MST\n",
      "Data saved for 123 at (35.502108, -105.64485666666667)\n",
      "Coordinates 35.53602600097656°N -99.24261474609375°E\n",
      "Timezone: America/Chicago, Abbreviation: CST\n",
      "Data saved for 123 at (35.502108, -99.19314222222222)\n",
      "Coordinates 35.53602600097656°N -92.65725708007812°E\n",
      "Timezone: America/Chicago, Abbreviation: CST\n",
      "Data saved for 123 at (35.502108, -92.74142777777777)\n",
      "Coordinates 35.53602600097656°N -86.30294799804688°E\n",
      "Timezone: America/Chicago, Abbreviation: CST\n",
      "Data saved for 123 at (35.502108, -86.28971333333334)\n",
      "Coordinates 35.53602600097656°N -79.8331298828125°E\n",
      "Timezone: America/New_York, Abbreviation: EST\n",
      "Data saved for 123 at (35.502108, -79.83799888888889)\n",
      "Coordinates 35.53602600097656°N -73.36328125°E\n",
      "Timezone: Etc/GMT+5, Abbreviation: -05\n",
      "Data saved for 123 at (35.502108, -73.38628444444444)\n",
      "Coordinates 35.53602600097656°N -66.89346313476562°E\n",
      "Timezone: Etc/GMT+4, Abbreviation: -04\n",
      "Data saved for 123 at (35.502108, -66.93457)\n",
      "Coordinates 38.277679443359375°N -125.02702331542969°E\n",
      "Timezone: Etc/GMT+8, Abbreviation: -08\n",
      "Data saved for 123 at (38.278558000000004, -125.0)\n",
      "Coordinates 38.277679443359375°N -118.45945739746094°E\n",
      "Timezone: America/Los_Angeles, Abbreviation: PST\n",
      "Data saved for 123 at (38.278558000000004, -118.54828555555555)\n",
      "Coordinates 38.277679443359375°N -112.01350402832031°E\n",
      "Timezone: America/Denver, Abbreviation: MST\n",
      "Data saved for 123 at (38.278558000000004, -112.0965711111111)\n",
      "Coordinates 38.277679443359375°N -105.56756591796875°E\n",
      "Timezone: America/Denver, Abbreviation: MST\n",
      "Data saved for 123 at (38.278558000000004, -105.64485666666667)\n",
      "Coordinates 38.277679443359375°N -99.24322509765625°E\n",
      "Timezone: America/Chicago, Abbreviation: CST\n",
      "Data saved for 123 at (38.278558000000004, -99.19314222222222)\n",
      "Coordinates 38.277679443359375°N -92.79730224609375°E\n",
      "Timezone: America/Chicago, Abbreviation: CST\n",
      "Data saved for 123 at (38.278558000000004, -92.74142777777777)\n",
      "Coordinates 38.277679443359375°N -86.229736328125°E\n",
      "Timezone: America/Indiana/Marengo, Abbreviation: EST\n",
      "Data saved for 123 at (38.278558000000004, -86.28971333333334)\n",
      "API request error: {'error': True, 'reason': 'Minutely API request limit exceeded. Please try again in one minute.'}\n",
      "Rate limit exceeded, waiting for 60 seconds before retrying.\n",
      "Coordinates 38.277679443359375°N -73.33782958984375°E\n",
      "Timezone: Etc/GMT+5, Abbreviation: -05\n",
      "Data saved for 123 at (38.278558000000004, -73.38628444444444)\n",
      "Coordinates 38.277679443359375°N -66.89187622070312°E\n",
      "Timezone: Etc/GMT+4, Abbreviation: -04\n",
      "Data saved for 123 at (38.278558000000004, -66.93457)\n",
      "Coordinates 41.089630126953125°N -124.97142028808594°E\n",
      "Timezone: Etc/GMT+8, Abbreviation: -08\n",
      "Data saved for 123 at (41.055008, -125.0)\n",
      "Coordinates 41.089630126953125°N -118.5428466796875°E\n",
      "Timezone: America/Los_Angeles, Abbreviation: PST\n",
      "Data saved for 123 at (41.055008, -118.54828555555555)\n",
      "Coordinates 41.089630126953125°N -112.11427307128906°E\n",
      "Timezone: America/Denver, Abbreviation: MST\n",
      "Data saved for 123 at (41.055008, -112.0965711111111)\n",
      "Coordinates 41.089630126953125°N -105.68569946289062°E\n",
      "Timezone: America/Denver, Abbreviation: MST\n",
      "Data saved for 123 at (41.055008, -105.64485666666667)\n",
      "Coordinates 41.089630126953125°N -99.25714111328125°E\n",
      "Timezone: America/Chicago, Abbreviation: CST\n",
      "Data saved for 123 at (41.055008, -99.19314222222222)\n",
      "Coordinates 41.089630126953125°N -92.69998168945312°E\n",
      "Timezone: America/Chicago, Abbreviation: CST\n",
      "Data saved for 123 at (41.055008, -92.74142777777777)\n",
      "API request error: {'error': True, 'reason': 'Minutely API request limit exceeded. Please try again in one minute.'}\n",
      "Rate limit exceeded, waiting for 60 seconds before retrying.\n",
      "Coordinates 41.089630126953125°N -79.84283447265625°E\n",
      "Timezone: America/New_York, Abbreviation: EST\n",
      "Data saved for 123 at (41.055008, -79.83799888888889)\n",
      "Coordinates 41.089630126953125°N -73.41427612304688°E\n",
      "Timezone: America/New_York, Abbreviation: EST\n",
      "Data saved for 123 at (41.055008, -73.38628444444444)\n",
      "Coordinates 41.089630126953125°N -66.98568725585938°E\n",
      "Timezone: Etc/GMT+4, Abbreviation: -04\n",
      "Data saved for 123 at (41.055008, -66.93457)\n",
      "Coordinates 43.83127975463867°N -124.99244689941406°E\n",
      "Timezone: Etc/GMT+8, Abbreviation: -08\n",
      "Data saved for 123 at (43.831458, -125.0)\n",
      "Coordinates 43.83127975463867°N -118.59304809570312°E\n",
      "Timezone: America/Los_Angeles, Abbreviation: PST\n",
      "Data saved for 123 at (43.831458, -118.54828555555555)\n",
      "Coordinates 43.83127975463867°N -112.0574951171875°E\n",
      "Timezone: America/Boise, Abbreviation: MST\n",
      "Data saved for 123 at (43.831458, -112.0965711111111)\n",
      "Coordinates 43.83127975463867°N -105.65809631347656°E\n",
      "Timezone: America/Denver, Abbreviation: MST\n",
      "Data saved for 123 at (43.831458, -105.64485666666667)\n",
      "Coordinates 43.83127975463867°N -99.25869750976562°E\n",
      "Timezone: America/Chicago, Abbreviation: CST\n",
      "Data saved for 123 at (43.831458, -99.19314222222222)\n",
      "Coordinates 43.83127975463867°N -92.72314453125°E\n",
      "Timezone: America/Chicago, Abbreviation: CST\n",
      "Data saved for 123 at (43.831458, -92.74142777777777)\n",
      "Coordinates 43.83127975463867°N -86.32376098632812°E\n",
      "Timezone: America/Detroit, Abbreviation: EST\n",
      "Data saved for 123 at (43.831458, -86.28971333333334)\n",
      "Coordinates 43.83127975463867°N -79.7882080078125°E\n",
      "Timezone: America/Toronto, Abbreviation: EST\n",
      "Data saved for 123 at (43.831458, -79.83799888888889)\n",
      "Coordinates 43.83127975463867°N -73.25265502929688°E\n",
      "Timezone: America/New_York, Abbreviation: EST\n",
      "Data saved for 123 at (43.831458, -73.38628444444444)\n",
      "API request error: {'reason': 'Minutely API request limit exceeded. Please try again in one minute.', 'error': True}\n",
      "Rate limit exceeded, waiting for 60 seconds before retrying.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from shapely.geometry import Point\n",
    "from surrounding_map_data import grab_data\n",
    "import warnings\n",
    "import xgboost as xgb\n",
    "import joblib  # Import joblib for saving and loading models\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from multiprocessing import Pool\n",
    "import pandas as pd\n",
    "from glob import glob \n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "global data_loc\n",
    "data_loc = '/work/bkelley/large_data/weather/'\n",
    "random_seed = 42\n",
    "\n",
    "\n",
    "def grab_evenly_spaced_us_points(n_points=100):\n",
    "    # Southwest corner (min latitude, min longitude)\n",
    "    min_lat = 24.396308\n",
    "    min_lon = -125.0\n",
    "    # Northeast corner (max latitude, max longitude)\n",
    "    max_lat = 49.384358\n",
    "    max_lon = -66.93457\n",
    "    # Create evenly spaced latitudes and longitudes\n",
    "    latitudes = np.linspace(min_lat, max_lat, int(np.sqrt(n_points)))\n",
    "    longitudes = np.linspace(min_lon, max_lon, int(np.sqrt(n_points)))\n",
    "    # Generate the grid of points (lat, lon)\n",
    "    points = []\n",
    "    for lat in latitudes:\n",
    "        for lon in longitudes:\n",
    "            points.append((lat, lon))\n",
    "    # Convert points to GeoDataFrame\n",
    "    geometry = [Point(lon, lat) for lat, lon in points]  # Point expects (x, y) = (lon, lat)\n",
    "    points_gdf = gpd.GeoDataFrame(geometry=geometry, crs=\"EPSG:4326\")  # WGS84 coordinate system\n",
    "    # Load the world map (No filtering by 'NAME' for United States)\n",
    "    world = gpd.read_file('/home/bkelley/capstone/weather_heat_maps/data/ne_10m_admin_0_countries/ne_10m_admin_0_countries.shp')\n",
    "    # Plot the map\n",
    "    plt = False\n",
    "    if plt == True:    \n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        world.plot(ax=ax, color='lightgrey', edgecolor='black')  # Plot world boundary\n",
    "        # Plot points\n",
    "        points_gdf.plot(ax=ax, color='red', marker='o', markersize=50)\n",
    "        # Set the axis limits to the bounding box of the United States\n",
    "        ax.set_xlim(min_lon-1, max_lon+1)\n",
    "        ax.set_ylim(min_lat-1, max_lat+1)\n",
    "        # Set equal aspect ratio to avoid distortion\n",
    "        ax.set_aspect('equal', adjustable='datalim')\n",
    "        plt.title('Evenly Spaced Points Inside the United States')\n",
    "        plt.xlabel('Longitude')\n",
    "        plt.ylabel('Latitude')\n",
    "        plt.show()\n",
    "    return points_gdf\n",
    "\n",
    "\n",
    "def grab_data_for_training(latlon_list, user_ID):\n",
    "    # Directory to save CSVs\n",
    "    data_loc = '/work/bkelley/large_data/weather/data'\n",
    "    # Extract lat, lon from GeoDataFrame points_gdf\n",
    "    # Run the data grabbing function for each lat/lon point\n",
    "    grab_data(latlon_list, user_ID)\n",
    "    # Ensure the data is saved with the lat/lon as the filename\n",
    "    for lat, lon in latlon_list:\n",
    "        # Ensure the filename is unique and uses lat lon as filename\n",
    "        lat_lon_filename = f\"{data_loc}{user_ID}_{lat}_{lon}_hourly.csv\"\n",
    "        # Check if the CSV is generated and save the data\n",
    "        if os.path.exists(lat_lon_filename):\n",
    "            print(f\"Data successfully saved for coordinates ({lat}, {lon}) at {lat_lon_filename}\")\n",
    "        else:\n",
    "            print(f\"Failed to save data for coordinates ({lat}, {lon})\")\n",
    "    return 0\n",
    "\n",
    "\n",
    "# Function to list all CSV files in the data directory\n",
    "def get_csv_files():\n",
    "    return [os.path.join(data_loc, f) for f in os.listdir(data_loc) if f.endswith('.csv')]\n",
    "\n",
    "\n",
    "# Function to train the model on a single CSV file\n",
    "def train_model(csv_file):\n",
    "    # Load data\n",
    "    data = pd.read_csv(csv_file)\n",
    "    \n",
    "    # Extract feature columns (excluding target columns like 'temperature_2m', 'weather_code', 'date')\n",
    "    x = data.drop(['temperature_2m', 'weather_code', 'date'], axis=1)\n",
    "    \n",
    "    # Get the list of all target columns (the columns to predict)\n",
    "    target_columns = [col for col in x.columns if col != 'temperature_2m']  # Excluding 'temperature_2m' as an example\n",
    "    \n",
    "    for target in target_columns:\n",
    "        print(f\"Training model for {target}...\")\n",
    "\n",
    "        y = data[[target]]  # Set the current column as the target\n",
    "        \n",
    "        # Convert categorical columns to 'category' type\n",
    "        cats = x.select_dtypes(exclude=np.number).columns.tolist()\n",
    "        for col in cats:\n",
    "            x[col] = x[col].astype('category')\n",
    "\n",
    "        # Split the data into training and testing sets (75%/25%)\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=random_seed)\n",
    "\n",
    "        # Create DMatrix objects for XGBoost\n",
    "        dtrain_reg = xgb.DMatrix(x_train, y_train, enable_categorical=True)\n",
    "        dtest_reg = xgb.DMatrix(x_test, y_test, enable_categorical=True)\n",
    "\n",
    "        # Define hyperparameters for XGBoost (GPU usage)\n",
    "        params = {\n",
    "            \"objective\": \"reg:squarederror\",\n",
    "            \"tree_method\": \"hist\",  # Use GPU for training\n",
    "            \"eval_metric\": \"rmse\",\n",
    "            \"device\": \"cuda\"\n",
    "        }\n",
    "        n = 1_000\n",
    "        evals = [(dtrain_reg, \"train\"), (dtest_reg, \"validation\")]\n",
    "\n",
    "        # Train the model with early stopping\n",
    "        model = xgb.train(\n",
    "            params=params,\n",
    "            dtrain=dtrain_reg,\n",
    "            num_boost_round=n,\n",
    "            evals=evals,\n",
    "            verbose_eval=100,\n",
    "            early_stopping_rounds=250\n",
    "        )\n",
    "        \n",
    "        print(f'Model training completed for {target}')\n",
    "        \n",
    "        # Save the trained model with lat/lon information from the filename\n",
    "        lat_lon = \"_\".join(os.path.basename(csv_file).split('_')[1:3])  # Extracts latitude and longitude\n",
    "        model_filename = f'{data_loc}/models/{lat_lon}_{target}_xgb_model.json'\n",
    "        \n",
    "        # Save the model\n",
    "        model.save_model(model_filename)\n",
    "        print(f'Model saved to {model_filename}.')\n",
    "\n",
    "        # Evaluate the model performance\n",
    "        preds = model.predict(dtest_reg)\n",
    "        rmse = mean_squared_error(y_test, preds, squared=False)\n",
    "        print(f\"RMSE for model {lat_lon}_{target}: {rmse:.3f}\")\n",
    "\n",
    "        # Perform 5-fold cross-validation\n",
    "        print(\"Performing cross validation\") \n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=random_seed)\n",
    "        results = []\n",
    "        for train_idx, val_idx in kf.split(x_train):\n",
    "            x_train_cv, x_val_cv = x_train.iloc[train_idx], x_train.iloc[val_idx]\n",
    "            y_train_cv, y_val_cv = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "            \n",
    "            dtrain_cv = xgb.DMatrix(x_train_cv, y_train_cv, enable_categorical=True)\n",
    "            dval_cv = xgb.DMatrix(x_val_cv, y_val_cv, enable_categorical=True)\n",
    "            \n",
    "            model_cv = xgb.train(params, dtrain_cv, num_boost_round=n, evals=[(dval_cv, \"validation\")], verbose_eval=False)\n",
    "            cv_preds = model_cv.predict(dval_cv)\n",
    "            cv_rmse = mean_squared_error(y_val_cv, cv_preds, squared=False)\n",
    "            results.append(cv_rmse)\n",
    "        \n",
    "        avg_rmse = np.mean(results)\n",
    "        print(f\"Average RMSE from 5-fold CV for {lat_lon}_{target}: {avg_rmse:.3f}\")\n",
    "\n",
    "\n",
    "# Function to train models\n",
    "def train_models():\n",
    "    # Get list of CSV files\n",
    "    csv_files = get_csv_files()\n",
    "\n",
    "    # Train models in parallel using multiprocessing\n",
    "    with Pool(processes=128) as pool:  # Use 128 processes (or more if you have more CPUs)\n",
    "        pool.map(train_model, csv_files)\n",
    "\n",
    "def predict(user_id):\n",
    "    model_dir = '/work/bkelley/large_data/weather/models'\n",
    "    data_dir = '/work/bkelley/large_data/weather'\n",
    "    prediction_dir = '/work/bkelley/large_data/weather/predictions'\n",
    "\n",
    "    # Loop through each model file in the model directory\n",
    "    for model_file in os.listdir(model_dir):\n",
    "        if model_file.endswith('_xgb_model.json'):\n",
    "            # Extract lat, lon from the model filename\n",
    "            lat, lon = model_file.split('_')[:2]\n",
    "            \n",
    "            # Load the corresponding hourly data file\n",
    "            hourly_file = os.path.join(data_dir, f\"{user_id}_{lat}_{lon}_hourly.csv\")\n",
    "            if os.path.exists(hourly_file):\n",
    "                # Read the hourly data CSV file\n",
    "                hourly_data = pd.read_csv(hourly_file)\n",
    "\n",
    "                # Check if necessary columns are present in the data\n",
    "                required_columns = [\n",
    "                    'temperature_2m', 'relative_humidity_2m', 'precipitation', 'rain', 'weather_code',\n",
    "                    'surface_pressure', 'cloud_cover', 'wind_speed_10m', 'wind_speed_100m', \n",
    "                    'wind_direction_10m', 'wind_direction_100m'\n",
    "                ]\n",
    "                if not all(col in hourly_data.columns for col in required_columns):\n",
    "                    print(f\"Missing columns in {hourly_file}, skipping this file.\")\n",
    "                    continue\n",
    "                \n",
    "                # Select the most recent data (e.g., last 24 hours)\n",
    "                input_data = hourly_data.tail(24).copy()  # Use last 24 hours\n",
    "\n",
    "                # Remove 'temperature_2m' and 'weather_code' if they were not in the training data\n",
    "                input_data = input_data.drop(columns=['temperature_2m', 'weather_code'], errors='ignore')\n",
    "\n",
    "                # Load the model\n",
    "                model_path = os.path.join(model_dir, model_file)\n",
    "                \n",
    "                if os.path.exists(model_path):\n",
    "                    model = xgb.XGBRegressor()\n",
    "                    try:\n",
    "                        model.load_model(model_path)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error loading model {model_file}: {e}\")\n",
    "                        continue  # Skip to the next model if loading fails\n",
    "                else:\n",
    "                    print(f\"Model file not found: {model_path}\")\n",
    "                    continue  # Skip to the next model if file doesn't exist\n",
    "\n",
    "                # Prepare input data for prediction (drop non-numeric or unnecessary columns)\n",
    "                features = input_data.drop(columns=['date'], errors='ignore')  # Drop 'date' if present\n",
    "\n",
    "                # Create a dictionary to hold predictions for each weather variable\n",
    "                predicted_data_dict = {\n",
    "                    'date': pd.date_range(datetime.now(), periods=24, freq='H')\n",
    "                }\n",
    "\n",
    "                # Loop through each weather feature and predict\n",
    "                weather_columns = [\n",
    "                    'temperature_2m', 'relative_humidity_2m', 'precipitation', 'rain', \n",
    "                    'surface_pressure', 'cloud_cover', 'wind_speed_10m', 'wind_speed_100m', \n",
    "                    'wind_direction_10m', 'wind_direction_100m'\n",
    "                ]\n",
    "\n",
    "                for col in weather_columns:\n",
    "                    # Generate predictions for the current weather feature\n",
    "                    predictions = model.predict(features)\n",
    "\n",
    "                    # Add the predictions to the dictionary\n",
    "                    predicted_data_dict[f'predicted_{col}'] = predictions\n",
    "\n",
    "                # Create the final DataFrame with predictions\n",
    "                predicted_data = pd.DataFrame(predicted_data_dict)\n",
    "\n",
    "                # Save the predictions to a CSV file in the prediction directory\n",
    "                output_file = os.path.join(prediction_dir, f\"{user_id}_{lat}_{lon}_predictions.csv\")\n",
    "                predicted_data.to_csv(output_file, index=False)\n",
    "                print(f\"Predictions saved for {user_id} at ({lat}, {lon})\")\n",
    "            else:\n",
    "                print(f\"Data file for {lat}, {lon} not found: {hourly_file}\")\n",
    "\n",
    "\n",
    "\n",
    "if __name__ ==\"__main__\":\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    points_gdf = grab_evenly_spaced_us_points()\n",
    "    grab_data_for_training(points_gdf, 123)\n",
    "    train_models()\n",
    "    # predict(123)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d1a9b5-c7f8-4067-ad30-ed05d16945c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
