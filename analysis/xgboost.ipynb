{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4f8f495-19bb-4b85-be14-7461ef7eef94",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'done' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 44\u001b[0m\n\u001b[1;32m     38\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m     39\u001b[0m model \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mtrain(\n\u001b[1;32m     40\u001b[0m    params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m     41\u001b[0m    dtrain\u001b[38;5;241m=\u001b[39mdtrain_reg,\n\u001b[1;32m     42\u001b[0m    num_boost_round\u001b[38;5;241m=\u001b[39mn,\n\u001b[1;32m     43\u001b[0m )\n\u001b[0;32m---> 44\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdone\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'done' is not defined"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "\n",
    " \n",
    "global LOC, data_path\n",
    "LOC = '/home/bkelley/capstone/data_collection/weather'\n",
    "data_path = '/home/bkelley/capstone/data_collection/weather/data/hourly_weather_with_temp_avg.csv'\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    # diamonds = sns.load_dataset(\"diamonds\"), for practice see https://www.datacamp.com/tutorial/xgboost-in-python\n",
    "    data = pd.read_csv(data_path)\n",
    "    # print(data.dtypes\n",
    "    # Extract feature and target arrays\n",
    "    # isolating the features into X and the target into y:\n",
    "    headers = data.columns\n",
    "    # print(headers)\n",
    "    x, y = data.drop('temperature_2m', axis=1), data[['surface_pressure_Pa']]\n",
    "    cats = x.select_dtypes(exclude=np.number).columns.tolist()\n",
    "    for col in cats:\n",
    "        x[col] = x[col].astype('category')\n",
    "    # print(x.dtypes)\n",
    "    # Split the data (size=0.25)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=1)\n",
    "    # Create regression matrices\n",
    "    dtrain_reg = xgb.DMatrix(x_train, y_train, enable_categorical=True)\n",
    "    dtest_reg = xgb.DMatrix(x_test, y_test, enable_categorical=True)\n",
    "    # Define hyperparameters\n",
    "    params = {\"objective\": \"reg:squarederror\", \"tree_method\": \"hist\"}  # NEED GPU HIST to run off of GPU\n",
    "    n = 100\n",
    "    model = xgb.train(\n",
    "       params=params,\n",
    "       dtrain=dtrain_reg,\n",
    "       num_boost_round=n,\n",
    "    )\n",
    "    print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abfeb4fe-3a57-447c-82d5-a723a8684229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of the base model: 27.297\n",
      "[0]\ttrain-rmse:494.89840\tvalidation-rmse:492.68427\n",
      "[5]\ttrain-rmse:85.22572\tvalidation-rmse:87.90217\n",
      "[10]\ttrain-rmse:20.22505\tvalidation-rmse:31.07321\n",
      "[15]\ttrain-rmse:12.30869\tvalidation-rmse:27.37471\n",
      "[20]\ttrain-rmse:10.72529\tvalidation-rmse:27.24115\n",
      "[25]\ttrain-rmse:9.98299\tvalidation-rmse:27.22857\n",
      "[30]\ttrain-rmse:9.33126\tvalidation-rmse:27.18570\n",
      "[35]\ttrain-rmse:8.87660\tvalidation-rmse:27.19500\n",
      "[40]\ttrain-rmse:8.43436\tvalidation-rmse:27.19528\n",
      "[45]\ttrain-rmse:8.11295\tvalidation-rmse:27.20592\n",
      "[50]\ttrain-rmse:7.83242\tvalidation-rmse:27.21670\n",
      "[55]\ttrain-rmse:7.54595\tvalidation-rmse:27.21600\n",
      "[60]\ttrain-rmse:7.32350\tvalidation-rmse:27.22715\n",
      "[65]\ttrain-rmse:7.12548\tvalidation-rmse:27.23827\n",
      "[70]\ttrain-rmse:6.92993\tvalidation-rmse:27.24295\n",
      "[75]\ttrain-rmse:6.76789\tvalidation-rmse:27.25400\n",
      "[78]\ttrain-rmse:6.67666\tvalidation-rmse:27.26058\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(dtest_reg)\n",
    "# print(len(preds))\n",
    "rmse = mean_squared_error(y_test, preds, squared=False)\n",
    "print(f\"RMSE of the base model: {rmse:.3f}\")\n",
    "params = {\"objective\": \"reg:squarederror\", \"tree_method\": \"hist\"}\n",
    "n = 200\n",
    "evals = [(dtrain_reg, \"train\"), (dtest_reg, \"validation\")]\n",
    "model = xgb.train(\n",
    "   params=params,\n",
    "   dtrain=dtrain_reg,\n",
    "   num_boost_round=n,\n",
    "   evals=evals,\n",
    "   verbose_eval=5, # print every 5\n",
    "   # Activate early stopping\n",
    "   early_stopping_rounds=50\n",
    ")\n",
    "\n",
    "\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02e5d62c-2680-4c2c-bad6-19c1014b191f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(29.907072535283824)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5 fold classification\n",
    "params = {\"objective\": \"reg:squarederror\", \"tree_method\": \"hist\"}\n",
    "n = 100\n",
    "\n",
    "results = xgb.cv(\n",
    "   params, dtrain_reg,\n",
    "   num_boost_round=n,\n",
    "   nfold=5,\n",
    "   early_stopping_rounds=35\n",
    ")\n",
    "results.head()\n",
    "best_rmse = results['test-rmse-mean'].min()\n",
    "best_rmse\n",
    "# np.float64(29.907072535283824)\n",
    "# re-train with all data (like above) using  xgb.train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d475dd-945e-4e58-b717-79cd7b695b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "# Prepare the data\n",
    "x, y = data.drop('temperature_2m', axis=1), data[['surface_pressure_Pa']]\n",
    "\n",
    "# Encode y to numeric\n",
    "y_encoded = OrdinalEncoder().fit_transform(y)\n",
    "\n",
    "# Count occurrences of each class in y_encoded\n",
    "y_encoded_df = pd.DataFrame(y_encoded, columns=['y_encoded'])\n",
    "class_counts = y_encoded_df['y_encoded'].value_counts()\n",
    "\n",
    "# Remove rows where the class count is less than 2\n",
    "valid_classes = class_counts[class_counts >= 2].index\n",
    "data_filtered = data[y_encoded_df['y_encoded'].isin(valid_classes)]\n",
    "\n",
    "# Split the data again\n",
    "x_filtered, y_filtered = data_filtered.drop('temperature_2m', axis=1), data_filtered[['surface_pressure_Pa']]\n",
    "\n",
    "# Re-encode y_filtered\n",
    "y_filtered_encoded = OrdinalEncoder().fit_transform(y_filtered)\n",
    "\n",
    "# Adjust labels to be in the range [0, num_class)\n",
    "y_filtered_encoded = y_filtered_encoded - y_filtered_encoded.min()\n",
    "\n",
    "# Ensure num_class is set correctly based on unique classes\n",
    "num_class = len(np.unique(y_filtered_encoded))\n",
    "\n",
    "# Extract text features and convert to categorical\n",
    "cats = x_filtered.select_dtypes(exclude=np.number).columns.tolist()\n",
    "for col in cats:\n",
    "    x_filtered[col] = x_filtered[col].astype('category')\n",
    "\n",
    "# Split the filtered data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_filtered, y_filtered_encoded, random_state=1, stratify=y_filtered_encoded)\n",
    "\n",
    "# Create classification matrices\n",
    "dtrain_clf = xgb.DMatrix(x_train, y_train, enable_categorical=True)\n",
    "dtest_clf = xgb.DMatrix(x_test, y_test, enable_categorical=True)\n",
    "\n",
    "# XGBoost parameters\n",
    "params = {\n",
    "    \"objective\": \"multi:softprob\",  # Softmax for multi-class classification\n",
    "    \"tree_method\": \"hist\",          # Efficient histogram-based tree method\n",
    "    \"num_class\": num_class,         # Set to the actual number of classes\n",
    "}\n",
    "\n",
    "n = 100  # Number of boosting rounds\n",
    "\n",
    "# Perform cross-validation\n",
    "results = xgb.cv(\n",
    "   params, dtrain_clf,\n",
    "   num_boost_round=n,\n",
    "   nfold=5,\n",
    "   metrics=[\"mlogloss\", \"auc\", \"merror\"],\n",
    ")\n",
    "\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d475211e-df75-4a54-8b2a-0242e5279eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8482.426000000007\n"
     ]
    }
   ],
   "source": [
    "# say x, y = data.drop('temperature_2m', axis=1), data[['surface_pressure_Pa']]\n",
    "# RMSE validatio of ~ 27\n",
    "print(data['surface_pressure_Pa'].max() - data['surface_pressure_Pa'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c8c7e94-9e04-4d36-952d-a8862dcabbd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104710.24\n",
      "96227.814\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "print(data['surface_pressure_Pa'].max())\n",
    "print(data['surface_pressure_Pa'].min())\n",
    "relative rmse = \n",
    "'''\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20f460f-6a9c-4990-9694-0107eb5ea372",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
